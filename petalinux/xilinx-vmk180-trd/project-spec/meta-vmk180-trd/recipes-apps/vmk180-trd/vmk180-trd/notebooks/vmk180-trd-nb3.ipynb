{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to configure a V4L2 device or video raw file from host machine through pcie, processes media content through 2D filter(optional) and transfers processed content to host via PCIe (or) display the content on hdmi monitor.\n",
    "\n",
    "Depending on the usecase following Gstreamer elements are used:\n",
    "* The `appsrc` element defined in xlnx_pcie_abstract python module is used to receive video frames from host       machine.\n",
    "* The `vvas_xfilter` element is used to implement a 2D convolution filter.\n",
    "* The `appsink` element defined in xlnx_pcie_abstract python module is used to send video frames to host mahine   in zero copy fashion.\n",
    "* The `kmsink` elemenet is used to display video frames on the hdmi monitor.\n",
    "\n",
    "Three different use cases are demonstrated using gstreamer based pcie Endpoint application.\n",
    "* Capture from v4l2 device (MIPI), process the video frames using vvas_xfilter plugin (or) bypass the vvas_xfilter   plugin and display on host machine using appsink.\n",
    "\n",
    "* Receive a video file from host machine using appsrc, process the received frames using vvas_xfilter plugin (or)   bypass vvas_xfilter plugin and send processed video frames to host machine through appsink.\n",
    "\n",
    "* Receive a video file from host machine using appsrc,process the received frames using vvas_xfilter plugin (or)   bypass vvas_xfilter plugin and display processed video frames on kmssink (HDMI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all python modules required for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "from threading import Thread\n",
    "\n",
    "import sys, time, gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "from gi.repository import GObject, GLib, Gst, GstApp\n",
    "\n",
    "# Importing enum for enumerations of usecases \n",
    "import enum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the VMK180 TRD notebook 3 (nb3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = \"nb3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing xlnx_pcie_abstract python module \n",
    "\n",
    "* xlnx_pcie_abstract python module is an abstraction which is used to create required `appsrc` and `appsink` elements, also helps to move media content between `src` --> with/bypass `vvas_xfilter` --> `sink` elements. \n",
    "\n",
    "* To move  media content between elements following wrapper functions are implement and are bind through Glib connect call. \n",
    "    - `need_data` callback is used to push data read from pcie to next elements i.e., `vvas_xfilter` (or) `appsink` (or) `kmssink` based on the control parameters received from host machine.\n",
    "    - `new_sample_cb` callback is used to pull data from `appsrc` (or) `vvas_xfilter` based on the control parameters received from host machine and pass the media content to appsink via pcie . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing xlnx_pcie_abstract python module\n",
    "import xlnx_pcie_abstract\n",
    "import ctypes\n",
    "from ctypes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different usecases are defined though enumeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Usecase(enum.IntEnum):\n",
    "    VGST_USECASE_TYPE_NONE = 0\n",
    "    VGST_USECASE_TYPE_MIPISRC_FLTR_HOST = 1\n",
    "    VGST_USECASE_TYPE_MIPISRC_TO_HOST = 2\n",
    "    VGST_USECASE_TYPE_APPSRC_FLTR_HOST = 3\n",
    "    VGST_USECASE_TYPE_APPSRC_TO_HOST = 4\n",
    "    VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK = 5\n",
    "    VGST_USECASE_TYPE_APPSRC_TO_KMSSINK = 6\n",
    "    VGST_USECASE_TYPE_MAX = 7\n",
    "\n",
    "pcie_fd = xlnx_pcie_abstract.PCIe_GetDevice()\n",
    "\n",
    "usecase = xlnx_pcie_abstract.PCIe_Getusecase(pcie_fd)\n",
    "if( (usecase.value <= Usecase.VGST_USECASE_TYPE_NONE)  and (usecase.value >= Usecase.VGST_USECASE_TYPE_NONE) ) :\n",
    "    raise Exception(\"Unsupported usecases\" )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Src , Filter, and Sink elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `xlnxvideosrc` or `appsrc` element based on the control information received from host machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.init(None)\n",
    "if ( usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) :\n",
    "        src_type = \"mipi\"\n",
    "        io_mode = \"dmabuf\"\n",
    "        src = Gst.ElementFactory.make(\"xlnxvideosrc\")\n",
    "        src.set_property(\"io-mode\", io_mode)\n",
    "        src.set_property(\"src-type\", src_type)\n",
    "        res_dict = {\n",
    "            \"1080p\" : (\"1920\", \"1080\"),\n",
    "            \"2160p\" : (\"3840\", \"2160\")\n",
    "            }\n",
    "        resp = xlnx_pcie_abstract.PCIe_GetResolution(pcie_fd)        \n",
    "        if(resp == 2160) :\n",
    "            res = \"2160p\" # Change the resolution string to 720p, 1080p, or 2160p (mipi only)\n",
    "            !xmediactl.sh\n",
    "        else :\n",
    "            res = \"1080p\"\n",
    "            !xmediactl_1080.sh\n",
    "        width = res_dict[res][0]\n",
    "        height = res_dict[res][1]\n",
    "        #print(\"Selected resolution: \" + width + \"x\" + height)\n",
    "        fmt = \"YUY2\"\n",
    "        caps = Gst.ElementFactory.make(\"capsfilter\")\n",
    "        cap = Gst.Caps.from_string(\"video/x-raw, width=\" + str(width) + \", height=\" + str(height) + \", format=\" + fmt)\n",
    "        caps.set_property(\"caps\", cap)\n",
    "\n",
    "elif (usecase.value >= Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_HOST)  :\n",
    "        src = Gst.ElementFactory.make(\"appsrc\")\n",
    "        caps = Gst.ElementFactory.make(\"capsfilter\")\n",
    "        xlnx_pcie_abstract.xlnx_pcieappsrc(src,caps)\n",
    "        xlnx_pcie_abstract.export_pciedmabuff(pcie_fd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `appsink` or `kmssink` element based on the control information received from host machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (usecase.value < Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK) :\n",
    "        sink = Gst.ElementFactory.make(\"appsink\")\n",
    "        xlnx_pcie_abstract.xlnx_pcieappsink(sink)\n",
    "        \n",
    "elif (usecase.value >= Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK )   :\n",
    "        #print(\"kmssink use case\")\n",
    "        driver_name = \"xlnx\"\n",
    "        plane_id = 38\n",
    "        xoff = 0 # Change this value to move the plane position in the x-direction\n",
    "        yoff = 0 # Change this value to move the plane position in the y-direction\n",
    "        width = int('3840', 10)\n",
    "        height = int('2160', 10)\n",
    "        render_rectangle = Gst.ValueArray((xoff, yoff, width, height))\n",
    "        hdmisink = Gst.ElementFactory.make(\"kmssink\")\n",
    "        hdmisink.set_property(\"driver-name\", driver_name)\n",
    "        hdmisink.set_property(\"plane-id\", plane_id)\n",
    "        hdmisink.set_property(\"render-rectangle\", render_rectangle)\n",
    "        hdmisink.set_property(\"sync\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vvas_xfilter element based on the control information received from host machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_filter = '0'\n",
    "if ( (usecase.value == Usecase.VGST_USECASE_TYPE_MIPISRC_FLTR_HOST ) or\n",
    "        (usecase.value == Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_HOST ) or \n",
    "            (usecase.value == Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK ) ) :\n",
    "    add_filter = '1'\n",
    "    \n",
    "    jsondir = \"/usr/share/vvas/vmk180-trd/\"\n",
    "    jfile = jsondir + \"kernel_xfilter2d_pl.json\"\n",
    "\n",
    "    filter2d = Gst.ElementFactory.make(\"vvas_xfilter\")\n",
    "    filter2d.set_property(\"kernels-config\", jfile)\n",
    "    plist = [\n",
    "        \"blur\",\n",
    "        \"edge\",\n",
    "        \"horizontal edge\",\n",
    "        \"vertical edge\",\n",
    "        \"emboss\",\n",
    "        \"horizontal gradient\",\n",
    "        \"vertical gradient\",\n",
    "        \"identity\",\n",
    "        \"sharpen\",\n",
    "        \"horizontal sobel\",\n",
    "        \"vertical sobel\",\n",
    "        \"custom\"\n",
    "        ]\n",
    "\n",
    "    def print_presets():\n",
    "        print(\"Supported filter presets:\\n\")\n",
    "        print('\\n'.join(plist) + '\\n')\n",
    "    \n",
    "    #print_presets()\n",
    "    def set_preset(val) :\n",
    "        if val in plist :\n",
    "            jstring = '{ \"filter_preset\" : \"' +  val + '\" }'\n",
    "            filter2d.set_property(\"dynamic-config\", jstring)\n",
    "        else :\n",
    "            raise Exception(\"Unsupported filter preset \\'\" + val + \"\\'\")\n",
    "\n",
    "    filter_preset = xlnx_pcie_abstract.PCIe_GetFilterPreset(pcie_fd)        \n",
    "    set_preset(plist[filter_preset.value])\n",
    "\n",
    "    def set_coeff(val):\n",
    "        jstring = '{ \"filter_coefficients\" : ' + val + ' }'\n",
    "        filter2d.set_property(\"dynamic-config\", jstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ``perf`` element which is used to measure and print the frame rate while the video pipeline is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = Gst.ElementFactory.make(\"perf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create and Run the GStreamer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline, add all elements, and link them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.Pipeline.new(nb)\n",
    "pipeline.add(src)\n",
    "\n",
    "if (usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST ) :\n",
    "    pipeline.add(caps)\n",
    "    if(add_filter == '1') :\n",
    "         pipeline.add(filter2d)\n",
    "    pipeline.add(perf)\n",
    "    pipeline.add(sink)\n",
    "    \n",
    "    src.link(caps)\n",
    "    if(add_filter == '1') :\n",
    "        caps.link(filter2d)\n",
    "        filter2d.link(perf)\n",
    "        perf.link(sink)\n",
    "    else :\n",
    "        caps.link(perf)\n",
    "        perf.link(sink)\n",
    "        \n",
    "\n",
    "if ( (usecase.value > Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) and\n",
    "         (usecase.value <= Usecase.VGST_USECASE_TYPE_APPSRC_TO_HOST) )   :\n",
    "    if(add_filter == '1') :\n",
    "         pipeline.add(filter2d)\n",
    "    pipeline.add(perf)\n",
    "    pipeline.add(sink)\n",
    "    \n",
    "    if(add_filter == '1') :\n",
    "        src.link(filter2d)\n",
    "        filter2d.link(perf)\n",
    "        perf.link(sink)\n",
    "    else :\n",
    "        src.link(perf)\n",
    "        perf.link(sink)\n",
    "\n",
    "if (usecase.value >= Usecase.VGST_USECASE_TYPE_APPSRC_FLTR_KMSSINK) :\n",
    "    if(add_filter == '1') :\n",
    "         pipeline.add(filter2d)\n",
    "    pipeline.add(perf)\n",
    "    pipeline.add(hdmisink)\n",
    "    \n",
    "    if(add_filter == '1') :\n",
    "        src.link(filter2d)\n",
    "        filter2d.link(perf)\n",
    "        perf.link(hdmisink)\n",
    "    else :\n",
    "        src.link(perf)\n",
    "        perf.link(hdmisink)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline (set to `PLAYING` state), create the main loop and listen to messages on the bus. Register the `bus_call` callback function with the `message` signal of the bus. Start the main loop.\n",
    "\n",
    "The video will be displayed on the monitor. The frame rate will be printed and updated below the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_call(bus, message, loop):\n",
    "    t = message.type\n",
    "    if t == Gst.MessageType.EOS:\n",
    "        sys.stdout.write(\"End-of-stream\\n\")\n",
    "        xlnx_pcie_abstract.xlnx_pciecleanup()\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        Gst.deinit()\n",
    "        loop.quit()\n",
    "    elif t == Gst.MessageType.INFO:\n",
    "        err, info = message.parse_info()\n",
    "        sys.stderr.write(\"Info: %s\\n\" % info)\n",
    "        clear_output(wait=True)\n",
    "    elif t == Gst.MessageType.ERROR:\n",
    "        err, debug = message.parse_error()\n",
    "        sys.stderr.write(\"Error: %s: %s\\n\" % (err, debug))\n",
    "        pipeline.set_state(Gst.State.NULL)\n",
    "        loop.quit()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_pipeline = 0\n",
    "\n",
    "if(usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) :\n",
    "    def thread_eos_status(threadname) :\n",
    "        global src\n",
    "        global exit_pipeline\n",
    "        while(exit_pipeline != 1) :\n",
    "            stop_feed = xlnx_pcie_abstract.stop_mipi_feed() \n",
    "            if (stop_feed) :\n",
    "                src.send_event(Gst.Event.new_eos())\n",
    "                xlnx_pcie_abstract.xlnx_pciecleanup()\n",
    "    \n",
    "    check_eos_thread = Thread(target=thread_eos_status, args=(\"thread_eos_status\",))\n",
    "\n",
    "pipeline.set_state(Gst.State.PLAYING);\n",
    "loop = GLib.MainLoop()\n",
    "bus = pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\",bus_call, loop)\n",
    "if(usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) :\n",
    "    check_eos_thread.start()\n",
    "    \n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    if (usecase.value <= Usecase.VGST_USECASE_TYPE_MIPISRC_TO_HOST) :\n",
    "            xlnx_pcie_abstract.xlnx_pciecleanup()\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you learned how to:\n",
    "1. Create a GStreamer pipeline that demonstrates how to capture video from a V4L2 device or receive media content from host machine, process media content from vvas_xfilter or bypass and display it on a hdmi monitor or display  processed/bypassed media content sent via pcie in zero copy fashion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>CopyrightÂ© 2019 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
